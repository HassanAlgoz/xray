{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hgoz/anaconda3/envs/06-image/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "# select the GPU device if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch_directml.is_available():\n",
    "    device = torch_directml.device(torch_directml.default_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 0.1307\n",
    "data_std = 0.3081\n",
    "transform = transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize((data_mean,), (data_std,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletMNIST(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, data):\n",
    "    self.data = data\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):  \n",
    "    anchor = self.data[index][0]\n",
    "    label = self.data[index][1]   \n",
    "\n",
    "    # Get positive sample \n",
    "    while True:     \n",
    "      x, y = self.data[random.randint(0, len(self.data) - 1)]\n",
    "      if y == label:\n",
    "        positive = x\n",
    "        break\n",
    "\n",
    "    # Get negative sample       \n",
    "    while True:\n",
    "        x, y = self.data[random.randint(0, len(self.data) - 1)]\n",
    "        if y != label:\n",
    "          negative = x\n",
    "          break\n",
    "\n",
    "    return anchor, positive, negative, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minst_train, mnist_valid = torch.utils.data.random_split(MNIST(root='data', train=True, download=True, transform=transform),\n",
    "                                                         [50_000, 10_000])\n",
    "trainset = TripletMNIST(minst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\n",
    "    'Zero',   \n",
    "    'One',    \n",
    "    'Two',   \n",
    "    'Three',  \n",
    "    'Four',    \n",
    "    'Five', \n",
    "    'Six',  \n",
    "    'Seven',  \n",
    "    'Eight',   \n",
    "    'Nine'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "anchor, positive, negative, label = trainset[1]\n",
    "\n",
    "# show images\n",
    "print('Label:', label)\n",
    "imshow(torchvision.utils.make_grid([anchor, positive, negative]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, patch_size, in_chans, embed_dim):\n",
    "        super(PatchEmbed, self).__init__()\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B, C, H, W = x.shape\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_size, d_model, patch_size, nhead, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = PatchEmbed(img_size*img_size, patch_size, 1, d_model)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model), num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.encoder(x)\n",
    "        return x.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, img_size, d_model, patch_size, nhead, num_layers, n_classes):\n",
    "        super(Model, self).__init__()\n",
    "        num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
    "\n",
    "        self.encoder = Encoder(img_size, d_model, patch_size, nhead, num_layers)\n",
    "        self.classifier = nn.Linear(d_model * num_patches, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        s = self.encoder(x)\n",
    "        preds = self.classifier(s)\n",
    "        return s, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_triplet = nn.TripletMarginWithDistanceLoss(margin=1.0) \n",
    "criterion_class = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    num_correct = (preds == labels).float().sum().item()\n",
    "    return num_correct / preds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19658"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = 'mnist_contrastive.pth'\n",
    "model = Model(img_size=28, d_model=32, patch_size=7, nhead=16, num_layers=2, n_classes=10)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_avg = 0\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "trainset_loader = DataLoader(trainset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "validset_loader = DataLoader(mnist_valid, batch_size=batch_size, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:28<00:00, 11.25it/s, loss=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:31<00:00, 10.89it/s, loss=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:31<00:00, 10.93it/s, loss=0.106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    tqdm_bar = tqdm(trainset_loader)\n",
    "    for data in tqdm_bar:\n",
    "        anchors = data[0].to(device)\n",
    "        positives = data[1].to(device)\n",
    "        negatives = data[2].to(device)\n",
    "        labels = data[3].to(device)\n",
    "    \n",
    "        embeddings, class_outputs = model(anchors)\n",
    "        pos_embeddings, _ = model(positives) \n",
    "        neg_embeddings, _ = model(negatives)  \n",
    "\n",
    "        # loss_triplet = criterion_triplet(embeddings, pos_embeddings, neg_embeddings)\n",
    "        loss_class = criterion_class(class_outputs, labels)\n",
    "\n",
    "        # loss = loss_triplet + loss_class\n",
    "        # loss = loss_triplet\n",
    "        loss = loss_class\n",
    "\n",
    "        loss_avg = 0.9 * loss_avg + 0.1 * loss.item() \n",
    "        tqdm_bar.set_postfix(loss=\"{:05.3f}\".format(loss_avg))\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in validset_loader:\n",
    "            images = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            _, outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            accuracies.append(calc_accuracy(preds, labels))\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(f\"Accuracy: {avg_accuracy:.3f}\")\n",
    "    torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(MODEL_PATH))\n",
    "# model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Model has been trained with just `loss_triplet` for `30` epochs\n",
    "2. Then it was trained with just `loss_Class` for `5` epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "mnist_test = MNIST(root='data', train=False, download=True, transform=transform)\n",
    "testset = mnist_test\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.971\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in validset_loader:\n",
    "        images = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        _, outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracies.append(calc_accuracy(preds, labels))\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Accuracy on test set: {avg_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: Zero  is 99.5 %\n",
      "Accuracy for class: One   is 99.2 %\n",
      "Accuracy for class: Two   is 97.4 %\n",
      "Accuracy for class: Three is 93.8 %\n",
      "Accuracy for class: Four  is 97.8 %\n",
      "Accuracy for class: Five  is 97.8 %\n",
      "Accuracy for class: Six   is 97.2 %\n",
      "Accuracy for class: Seven is 96.9 %\n",
      "Accuracy for class: Eight is 94.4 %\n",
      "Accuracy for class: Nine  is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        _, outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracies.append(calc_accuracy(preds, labels))\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, preds):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "06-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
